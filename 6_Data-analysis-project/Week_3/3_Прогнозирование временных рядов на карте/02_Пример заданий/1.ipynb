{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801e2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\randm\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from category_encoders) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from category_encoders) (0.13.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from category_encoders) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from category_encoders) (0.24.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\randm\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\randm\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d73f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder, OrdinalEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d0fcb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ROeipLp</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>K2SqEo9</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>am14IcfM7tWLrUmRT52KtA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ZV0mFX7</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1E9D3Yd</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>5Acm</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4956.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CBA87dl</td>\n",
       "      <td>oslk</td>\n",
       "      <td>TX2AGfT</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kwS7</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7630.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4UxGlow</td>\n",
       "      <td>oslk</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>cXsjB1v</td>\n",
       "      <td>oslk</td>\n",
       "      <td>qWjjxQb</td>\n",
       "      <td>M_8D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>szEZ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var9  Var10  Var11  ...  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN   714.0   7.0   NaN    NaN    NaN  ...   \n",
       "1   NaN   NaN   NaN   NaN   NaN  3059.0   7.0   NaN    NaN    NaN  ...   \n",
       "2   NaN   NaN   NaN   NaN   NaN  4956.0   7.0   NaN    NaN    NaN  ...   \n",
       "3   NaN   NaN   NaN   NaN   NaN  7630.0   7.0   NaN    NaN    NaN  ...   \n",
       "4   NaN   NaN   NaN   NaN   NaN  1022.0   7.0   NaN    NaN    NaN  ...   \n",
       "\n",
       "    Var220  Var221   Var222      Var223  Var224  Var225  Var226  Var227  \\\n",
       "0  ROeipLp    zCkv  K2SqEo9  jySVZNlOJy     NaN     NaN    WqMG    6fzt   \n",
       "1  ZV0mFX7    oslk  1E9D3Yd  jySVZNlOJy     NaN    ELof    5Acm    RAYp   \n",
       "2  CBA87dl    oslk  TX2AGfT  jySVZNlOJy     NaN     NaN    kwS7    RAYp   \n",
       "3  4UxGlow    oslk  catzS2D  LM8l689qOp     NaN    ELof    WqMG    ZI9m   \n",
       "4  cXsjB1v    oslk  qWjjxQb        M_8D     NaN    ELof    szEZ    RAYp   \n",
       "\n",
       "                   Var228  Var229  \n",
       "0  am14IcfM7tWLrUmRT52KtA     NaN  \n",
       "1           F2FyR07IdsN7I    am7c  \n",
       "2           F2FyR07IdsN7I     NaN  \n",
       "3           ib5G6X1eUxUn6    am7c  \n",
       "4           F2FyR07IdsN7I    am7c  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train-data.csv')\n",
    "\n",
    "# Удалим пустые колонки и индексы.  \n",
    "data = data.dropna(axis=1, how='all').drop(columns=['Unnamed: 0'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52762eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = data.iloc[: , :data.columns.get_loc(\"Var191\")].columns\n",
    "categorical_features = data.iloc[: , data.columns.get_loc(\"Var191\"):].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be425ebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn\n",
       "0     -1\n",
       "1     -1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('train-labels.csv')\n",
    "labels = labels.drop(columns=['Unnamed: 0'])\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eda570",
   "metadata": {},
   "source": [
    "# Base pipeline\n",
    "Создадим pipline для подготовки данных. Используем простые методы: запишем нули в пропуски, OneHotEncoder для категорий.\n",
    "Определим алгоритмы, параметры кроссвалидации, метрики и вспомогательные функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4dbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "num_transformer = make_pipeline(\n",
    "    SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0),\n",
    "    StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "      SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='empty'),\n",
    "      OneHotEncoder(handle_unknown = 'ignore')) \n",
    "\n",
    "preprocessor_all_features=make_column_transformer(\n",
    "    (num_transformer, num_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    ")\n",
    "\n",
    "\n",
    "# Метрики\n",
    "# У нас есть своя метрика, поэтому просто списком передать нельзя.\n",
    "metrics_={\n",
    "    'f2': metrics.make_scorer(metrics.fbeta_score, beta=2),\n",
    "    'f1': metrics.make_scorer(metrics.f1_score),\n",
    "    'recall': metrics.make_scorer(metrics.recall_score),\n",
    "    'roc_auc': metrics.make_scorer(metrics.roc_auc_score),\n",
    "}\n",
    "\n",
    "\n",
    "# Классификаторы\n",
    "classifiers=[\n",
    "    RidgeClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "\n",
    "# Параметры\n",
    "k_fold = 5\n",
    "\n",
    "\n",
    "# Хелперы\n",
    "def print_report(clf, scores):\n",
    "    print(clf)\n",
    "    for score, values in scores.items():\n",
    "        print(f'{score} mean: {round(np.mean(values), 5)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18449b3a",
   "metadata": {},
   "source": [
    "Запустим базовый pipeline на всей выборке - получим значения метрик относительно которых будем делать дальнейшие изменения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f94e70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier()\n",
      "fit_time mean: 15.57956\n",
      "score_time mean: 0.3493\n",
      "test_f2 mean: 0.04859\n",
      "test_f1 mean: 0.06341\n",
      "test_recall mean: 0.04204\n",
      "test_roc_auc mean: 0.5098\n",
      "\n",
      "LogisticRegression()\n",
      "fit_time mean: 2.72234\n",
      "score_time mean: 0.35832\n",
      "test_f2 mean: 0.04866\n",
      "test_f1 mean: 0.06862\n",
      "test_recall mean: 0.04076\n",
      "test_roc_auc mean: 0.51451\n",
      "\n",
      "SGDClassifier()\n",
      "fit_time mean: 1.31141\n",
      "score_time mean: 0.34647\n",
      "test_f2 mean: 0.06335\n",
      "test_f1 mean: 0.07764\n",
      "test_recall mean: 0.0569\n",
      "test_roc_auc mean: 0.51637\n",
      "\n",
      "RandomForestClassifier()\n",
      "fit_time mean: 27.14385\n",
      "score_time mean: 1.13081\n",
      "test_f2 mean: 0.00053\n",
      "test_f1 mean: 0.00085\n",
      "test_recall mean: 0.00042\n",
      "test_roc_auc mean: 0.50021\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "fit_time mean: 56.97191\n",
      "score_time mean: 0.3649\n",
      "test_f2 mean: 0.00738\n",
      "test_f1 mean: 0.01157\n",
      "test_recall mean: 0.00594\n",
      "test_roc_auc mean: 0.50226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor_all_features),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_validate(pipeline, data, labels, cv=k_fold, scoring=metrics_, n_jobs=-1)\n",
    "    \n",
    "    print_report(clf, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c6e69",
   "metadata": {},
   "source": [
    "Значение метрик около нуля. Сначала попробуем выкинуть признаки с наибольшим кол-вом пропусков. Предположим, что если пропусков больше 95%, то признак можно исключить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7ace903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_na_perc(df, percent):\n",
    "    na_in_perc = df.isna().sum() / len(df) * 100\n",
    "    return na_in_perc[na_in_perc < percent].index\n",
    "\n",
    "def get_cross_featues(a_featues, b_featues):\n",
    "    return [a for a in a_featues if a in b_featues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52fee1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_95 = get_features_na_perc(data, 95)\n",
    "\n",
    "preprocessor_95 = make_column_transformer(\n",
    "    (num_transformer, get_cross_featues(num_features, features_95)),\n",
    "    (categorical_transformer, get_cross_featues(categorical_features, features_95)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ac4ed7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier()\n",
      "fit_time mean: 7.56057\n",
      "score_time mean: 0.18152\n",
      "test_f2 mean: 0.04246\n",
      "test_f1 mean: 0.05617\n",
      "test_recall mean: 0.03652\n",
      "test_roc_auc mean: 0.50789\n",
      "\n",
      "LogisticRegression()\n",
      "fit_time mean: 2.28008\n",
      "score_time mean: 0.18304\n",
      "test_f2 mean: 0.04227\n",
      "test_f1 mean: 0.06029\n",
      "test_recall mean: 0.03524\n",
      "test_roc_auc mean: 0.51236\n",
      "\n",
      "SGDClassifier()\n",
      "fit_time mean: 1.27543\n",
      "score_time mean: 0.20761\n",
      "test_f2 mean: 0.03135\n",
      "test_f1 mean: 0.04587\n",
      "test_recall mean: 0.0259\n",
      "test_roc_auc mean: 0.50931\n",
      "\n",
      "RandomForestClassifier()\n",
      "fit_time mean: 32.62009\n",
      "score_time mean: 0.64823\n",
      "test_f2 mean: 0.0\n",
      "test_f1 mean: 0.0\n",
      "test_recall mean: 0.0\n",
      "test_roc_auc mean: 0.5\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "fit_time mean: 28.64177\n",
      "score_time mean: 0.19596\n",
      "test_f2 mean: 0.01002\n",
      "test_f1 mean: 0.01571\n",
      "test_recall mean: 0.00807\n",
      "test_roc_auc mean: 0.50334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor_95),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_validate(pipeline, data, np.ravel(labels), cv=k_fold, scoring=metrics_, n_jobs=-1)\n",
    "    \n",
    "    print_report(clf, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c83e2",
   "metadata": {},
   "source": [
    "Значимых изменений нет. Мы знаем, что у нас не сбалансированные классы -1/1. Попробуем сделать простой оверсемплинг, основанный на случайном выборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bb326f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59290, 59290)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([data, labels], axis=1)\n",
    "\n",
    "origin_not_churn = df[df.Churn == -1]\n",
    "origin_churn = df[df.Churn == 1]\n",
    "\n",
    "churn_samples = origin_churn.sample(len(origin_not_churn), replace=True, random_state=0)\n",
    "oversampled = pd.concat([origin_not_churn, churn_samples], axis=0)\n",
    "\n",
    "len(oversampled.Churn == -1), len(oversampled.Churn == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2ea0c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier()\n",
      "fit_time mean: 81.90059\n",
      "score_time mean: 0.44981\n",
      "test_f2 mean: 0.97522\n",
      "test_f1 mean: 0.94269\n",
      "test_recall mean: 0.99818\n",
      "test_roc_auc mean: 0.93932\n",
      "\n",
      "LogisticRegression()\n",
      "fit_time mean: 7.77205\n",
      "score_time mean: 0.46597\n",
      "test_f2 mean: 0.91071\n",
      "test_f1 mean: 0.88677\n",
      "test_recall mean: 0.92741\n",
      "test_roc_auc mean: 0.88158\n",
      "\n",
      "SGDClassifier()\n",
      "fit_time mean: 4.85593\n",
      "score_time mean: 0.44526\n",
      "test_f2 mean: 0.95056\n",
      "test_f1 mean: 0.91736\n",
      "test_recall mean: 0.97413\n",
      "test_roc_auc mean: 0.91213\n",
      "\n",
      "RandomForestClassifier()\n",
      "fit_time mean: 112.22056\n",
      "score_time mean: 1.33056\n",
      "test_f2 mean: 0.99985\n",
      "test_f1 mean: 0.99973\n",
      "test_recall mean: 0.99993\n",
      "test_roc_auc mean: 0.99973\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "fit_time mean: 92.22338\n",
      "score_time mean: 0.46674\n",
      "test_f2 mean: 0.72777\n",
      "test_f1 mean: 0.71556\n",
      "test_recall mean: 0.73614\n",
      "test_roc_auc mean: 0.70737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor_all_features),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_validate(pipeline, oversampled.drop(columns=['Churn']), np.ravel(oversampled.Churn),\n",
    "                            cv=k_fold, scoring=metrics_, n_jobs=-1)\n",
    "    \n",
    "    print_report(clf, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527bee3",
   "metadata": {},
   "source": [
    "Оверсемплинг сереьезно увеличил качество модели. Буем рассматривать RandomForestClassifier, SGDClassifier. Нужно доработать препроцессинг данных (пропуски, энкодинг), отобрать фичи, и рассмотреть другие алгоритмы оверсемплинга."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
